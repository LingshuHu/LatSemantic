{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes are adapted from https://github.com/Garrafao/TRIPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.sparse import csr_matrix, load_npz, save_npz, linalg\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.word2vec import PathLineSentences\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import dok_matrix\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "#from utils_ import Space\n",
    "#import vocab\n",
    "#import count\n",
    "#import random\n",
    "#import multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Space(object):\n",
    "    \"\"\"\n",
    "    Load and save Space objects.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, path=None, matrix=csr_matrix([]), rows=[], columns=[], format='npz'):\n",
    "        \"\"\"\n",
    "        Can be either initialized (i) by providing a path, (ii) by providing a matrix, rows and columns, or (iii) by providing neither, then an empty instance is created\n",
    "        `path` should be path to a matrix in npz format, expects rows and columns in same folder at '[path]_rows' and '[path]_columns'\n",
    "        `rows` list with row names\n",
    "        `columns` list with column names\n",
    "        `format` format of matrix, can be either of 'npz' or 'w2v'\n",
    "        \"\"\"\n",
    "        \n",
    "        if path!=None:\n",
    "            if format=='npz':\n",
    "                # Load matrix\n",
    "                matrix = load_npz(path)\n",
    "                # Load rows\n",
    "                with open(path + '_rows', 'rb') as f:\n",
    "                    rows = pickle.load(f)\n",
    "                # Load columns\n",
    "                with open(path + '_columns', 'rb') as f:\n",
    "                    columns = pickle.load(f)\n",
    "            elif format=='w2v':\n",
    "                matrix_array = np.loadtxt(path, dtype=object, delimiter=' ', skiprows=1, encoding='utf-8')\n",
    "                matrix = matrix_array[:,1:].astype(np.float)\n",
    "                rows = list(matrix_array[:,0].flatten())\n",
    "                columns = []             \n",
    "            else:      \n",
    "                message = \"Matrix format {0} unknown.\"\n",
    "                logging.error(message.format(format))\n",
    "\n",
    "        row2id = {r:i for i, r in enumerate(rows)}\n",
    "        id2row = {i:r for i, r in enumerate(rows)}\n",
    "        column2id = {c:i for i, c in enumerate(columns)}\n",
    "        id2column = {i:c for i, c in enumerate(columns)}\n",
    "\n",
    "        self.matrix = csr_matrix(matrix)\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.row2id = row2id\n",
    "        self.id2row = id2row\n",
    "        self.column2id = column2id\n",
    "        self.id2column = id2column      \n",
    "        \n",
    "    def save(self, path, format='npz'):\n",
    "        \"\"\"\n",
    "        `path` saves matrix at path in npz format, saves rows and columns as pickled lists in same folder at '[path]_rows' and '[path]_columns'\n",
    "        `format` format of matrix, can be either of 'npz' or 'w2v'\n",
    "        \"\"\"\n",
    "        \n",
    "        if format=='npz':       \n",
    "            # Save matrix\n",
    "            with open(path, 'wb') as f:\n",
    "                save_npz(f, self.matrix)    \n",
    "            # Save rows\n",
    "            with open(path + '_rows', 'wb') as f:\n",
    "                pickle.dump(self.rows, f)\n",
    "            # Save columns\n",
    "            with open(path + '_columns', 'wb') as f:\n",
    "                pickle.dump(self.columns, f)\n",
    "        elif format=='w2v':\n",
    "            matrix = self.matrix.toarray().astype(object)\n",
    "            rows = np.array(self.rows)\n",
    "            r, d = matrix.shape\n",
    "            rows = rows.reshape(-1,1)\n",
    "            matrix = np.concatenate((rows, matrix), axis=1)\n",
    "            np.savetxt(path, matrix, fmt=[\"%s\"] + ['%.16g',]*d, delimiter=' ', newline='\\n', header='%d %d' %(r, d), comments='', encoding='utf-8')\n",
    "        else:      \n",
    "            message = \"Matrix format {0} unknown.\"\n",
    "            logging.error(message.format(format))\n",
    "\n",
    "    def l2_normalize(self):\n",
    "        '''\n",
    "        L2-normalize all vectors in the matrix.\n",
    "        '''\n",
    "        l2norm = linalg.norm(self.matrix, axis=1, ord=2)\n",
    "        l2norm[l2norm==0.0] = 1.0 # Convert 0 values to 1\n",
    "        self.matrix = csr_matrix(self.matrix/l2norm.reshape(len(l2norm),1))\n",
    "\n",
    "    def mean_center(self):\n",
    "        '''\n",
    "        Mean center all columns in the matrix.\n",
    "        '''\n",
    "        avg = np.mean(self.matrix, axis = 0)\n",
    "        self.matrix = csr_matrix(self.matrix - avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get vocabulary\n",
    "sentences = PathLineSentences(\"../data_week_text/russia/covid_russia_week11_2020-4-3.txt\")\n",
    "vocabulary = sorted(list(set([word for sentence in sentences for word in sentence if len(sentence)>1]))) # Skip one-word sentences to avoid zero-vectors\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count occurance with a window\n",
    "def get_count_matrix(sentences, vocabulary, windowSize = 7): \n",
    "    w2i = {w: i for i, w in enumerate(vocabulary)}\n",
    "\n",
    "    # Initialize co-occurrence matrix as dictionary\n",
    "    cooc_mat = defaultdict(lambda: 0)\n",
    "\n",
    "    # Get counts from corpus\n",
    "    #logging.info(\"Counting context words\")\n",
    "    #sentences = PathLineSentences(corpDir)\n",
    "    for sentence in sentences:\n",
    "        for i, word in enumerate(sentence):\n",
    "            try:\n",
    "                windex = w2i[word]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            lowerWindowSize = max(i-windowSize, 0)\n",
    "            upperWindowSize = min(i+windowSize, len(sentence))\n",
    "            window = sentence[lowerWindowSize:i] + sentence[i+1:upperWindowSize+1]\n",
    "            if len(window)==0: # Skip one-word sentences\n",
    "                continue\n",
    "            for contextWord in window:\n",
    "                try:\n",
    "                    cindex = w2i[contextWord]\n",
    "                except KeyError:\n",
    "                    continue                \n",
    "                cooc_mat[(windex,cindex)] += 1\n",
    "\n",
    "\n",
    "    # Convert dictionary to sparse matrix\n",
    "    cooc_mat_sparse = dok_matrix((len(vocabulary),len(vocabulary)), dtype=float)\n",
    "    try:\n",
    "        cooc_mat_sparse.update(cooc_mat)\n",
    "    except NotImplementedError:\n",
    "        cooc_mat_sparse._update(cooc_mat)\n",
    "\n",
    "    countSpace = Space(matrix=cooc_mat_sparse, rows=vocabulary, columns=vocabulary)\n",
    "    countMatrix = countSpace.matrix\n",
    "    return(countMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate random matrix\n",
    "def get_random_matrix(vocabulary, dim = 100):\n",
    "    #dim: dimention of word embedding\n",
    "    randomMatrix = sparse_random_matrix(dim,len(vocabulary)).toarray().T\n",
    "    randomMatrix = Space(matrix=randomMatrix, rows=vocabulary, columns=[])\n",
    "    randomMatrix = randomMatrix.matrix\n",
    "    return(randomMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16322"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16322"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get embedding\n",
    "def get_embedding_space(countMatrix, randomMatrix, l2 = True, mc = True):\n",
    "    embedding = np.dot(countMatrix,randomMatrix)    \n",
    "    embeddingSpace = Space(matrix=embedding, rows=vocabulary, columns=[]) # rows = countSpace.rows\n",
    "    if l2: \n",
    "        embeddingSpace.l2_normalize()\n",
    "    if mc:\n",
    "        embeddingSpace.mean_center()\n",
    "    return(embeddingSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get similarity\n",
    "def get_simi(embeddingSpace, wd1, wd2, negative = False):\n",
    "    matrix = embeddingSpace.matrix\n",
    "    row2id = embeddingSpace.row2id\n",
    "    try:\n",
    "        v1 = matrix[row2id[wd1]].toarray().flatten()\n",
    "        v2 = matrix[row2id[wd2]].toarray().flatten()\n",
    "        if negative:\n",
    "            simi_score = 1-cosine_distance(v1, v2)\n",
    "        else:\n",
    "            simi_score = 1-(cosine_distance(v1, v2)/2)\n",
    "    except KeyError:\n",
    "        simi_score = 9\n",
    "    \n",
    "    return(simi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "countMatrix = get_count_matrix(sentences = sentences, vocabulary = vocabulary, windowSize = 7)\n",
    "randomMatrix = get_random_matrix(dim = 100, vocabulary = vocabulary)\n",
    "embeddingSpace = get_embedding_space(countMatrix = countMatrix, randomMatrix = randomMatrix, l2 = True, mc = True)\n",
    "simi_score = get_simi(embeddingSpace = embeddingSpace, wd1 = \"covid19\", wd2 = \"sdifjsiodjfiosdj\")\n",
    "simi_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load all keywords pairs\n",
    "with open('../data/all_keywords_pairs.json', 'r') as json_file:\n",
    "    all_pairs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Russian Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['covid_russia_week01_2020-01-24.txt',\n",
       " 'covid_russia_week02_2020-01-31.txt',\n",
       " 'covid_russia_week03_2020-02-07.txt',\n",
       " 'covid_russia_week04_2020-02-14.txt',\n",
       " 'covid_russia_week05_2020-02-21.txt',\n",
       " 'covid_russia_week06_2020-02-28.txt',\n",
       " 'covid_russia_week07_2020-03-06.txt',\n",
       " 'covid_russia_week08_2020-03-13.txt',\n",
       " 'covid_russia_week09_2020-03-20.txt',\n",
       " 'covid_russia_week10_2020-03-27.txt',\n",
       " 'covid_russia_week11_2020-04-03.txt',\n",
       " 'covid_russia_week12_2020-04-10.txt',\n",
       " 'covid_russia_week13_2020-04-17.txt',\n",
       " 'covid_russia_week14_2020-04-24.txt',\n",
       " 'covid_russia_week15_2020-05-01.txt',\n",
       " 'covid_russia_week16_2020-05-08.txt',\n",
       " 'covid_russia_week17_2020-05-15.txt',\n",
       " 'covid_russia_week18_2020-05-22.txt',\n",
       " 'covid_russia_week19_2020-05-29.txt',\n",
       " 'covid_russia_week20_2020-06-05.txt',\n",
       " 'covid_russia_week21_2020-06-12.txt',\n",
       " 'covid_russia_week22_2020-06-19.txt',\n",
       " 'covid_russia_week23_2020-06-26.txt',\n",
       " 'covid_russia_week24_2020-07-03.txt',\n",
       " 'covid_russia_week25_2020-07-10.txt',\n",
       " 'covid_russia_week26_2020-07-17.txt',\n",
       " 'covid_russia_week27_2020-07-24.txt',\n",
       " 'covid_russia_week28_2020-07-31.txt',\n",
       " 'covid_russia_week29_2020-08-07.txt',\n",
       " 'covid_russia_week30_2020-08-14.txt',\n",
       " 'covid_russia_week31_2020-08-21.txt',\n",
       " 'covid_russia_week32_2020-08-28.txt',\n",
       " 'covid_russia_week33_2020-09-04.txt',\n",
       " 'covid_russia_week34_2020-09-11.txt',\n",
       " 'covid_russia_week35_2020-09-18.txt',\n",
       " 'covid_russia_week36_2020-09-25.txt',\n",
       " 'covid_russia_week37_2020-10-02.txt',\n",
       " 'covid_russia_week38_2020-10-09.txt',\n",
       " 'covid_russia_week39_2020-10-16.txt',\n",
       " 'covid_russia_week40_2020-10-23.txt',\n",
       " 'covid_russia_week41_2020-10-30.txt',\n",
       " 'covid_russia_week42_2020-11-06.txt',\n",
       " 'covid_russia_week43_2020-11-13.txt',\n",
       " 'covid_russia_week44_2020-11-20.txt',\n",
       " 'covid_russia_week45_2020-11-27.txt',\n",
       " 'covid_russia_week46_2020-12-04.txt',\n",
       " 'covid_russia_week47_2020-12-11.txt',\n",
       " 'covid_russia_week48_2020-12-18.txt',\n",
       " 'covid_russia_week49_2020-12-25.txt',\n",
       " 'covid_russia_week50_2021-01-01.txt',\n",
       " 'covid_russia_week51_2021-01-08.txt',\n",
       " 'covid_russia_week52_2021-01-15.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../data_week_text/russia')\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_russia_week01_2020-01-24.txt\n",
      "covid_russia_week02_2020-01-31.txt\n",
      "covid_russia_week03_2020-02-07.txt\n",
      "covid_russia_week04_2020-02-14.txt\n",
      "covid_russia_week05_2020-02-21.txt\n",
      "covid_russia_week06_2020-02-28.txt\n",
      "covid_russia_week07_2020-03-06.txt\n",
      "covid_russia_week08_2020-03-13.txt\n",
      "covid_russia_week09_2020-03-20.txt\n",
      "covid_russia_week10_2020-03-27.txt\n",
      "covid_russia_week11_2020-04-03.txt\n",
      "covid_russia_week12_2020-04-10.txt\n",
      "covid_russia_week13_2020-04-17.txt\n",
      "covid_russia_week14_2020-04-24.txt\n",
      "covid_russia_week15_2020-05-01.txt\n",
      "covid_russia_week16_2020-05-08.txt\n",
      "covid_russia_week17_2020-05-15.txt\n",
      "covid_russia_week18_2020-05-22.txt\n",
      "covid_russia_week19_2020-05-29.txt\n",
      "covid_russia_week20_2020-06-05.txt\n",
      "covid_russia_week21_2020-06-12.txt\n",
      "covid_russia_week22_2020-06-19.txt\n",
      "covid_russia_week23_2020-06-26.txt\n",
      "covid_russia_week24_2020-07-03.txt\n",
      "covid_russia_week25_2020-07-10.txt\n",
      "covid_russia_week26_2020-07-17.txt\n",
      "covid_russia_week27_2020-07-24.txt\n",
      "covid_russia_week28_2020-07-31.txt\n",
      "covid_russia_week29_2020-08-07.txt\n",
      "covid_russia_week30_2020-08-14.txt\n",
      "covid_russia_week31_2020-08-21.txt\n",
      "covid_russia_week32_2020-08-28.txt\n",
      "covid_russia_week33_2020-09-04.txt\n",
      "covid_russia_week34_2020-09-11.txt\n",
      "covid_russia_week35_2020-09-18.txt\n",
      "covid_russia_week36_2020-09-25.txt\n",
      "covid_russia_week37_2020-10-02.txt\n",
      "covid_russia_week38_2020-10-09.txt\n",
      "covid_russia_week39_2020-10-16.txt\n",
      "covid_russia_week40_2020-10-23.txt\n",
      "covid_russia_week41_2020-10-30.txt\n",
      "covid_russia_week42_2020-11-06.txt\n",
      "covid_russia_week43_2020-11-13.txt\n",
      "covid_russia_week44_2020-11-20.txt\n",
      "covid_russia_week45_2020-11-27.txt\n",
      "covid_russia_week46_2020-12-04.txt\n",
      "covid_russia_week47_2020-12-11.txt\n",
      "covid_russia_week48_2020-12-18.txt\n",
      "covid_russia_week49_2020-12-25.txt\n",
      "covid_russia_week50_2021-01-01.txt\n",
      "covid_russia_week51_2021-01-08.txt\n",
      "covid_russia_week52_2021-01-15.txt\n"
     ]
    }
   ],
   "source": [
    "## generate embedding spaces with all data\n",
    "results = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    ## RI embedding\n",
    "    sentences = PathLineSentences('../data_week_text/russia/'+file)\n",
    "    vocabulary = sorted(list(set([word for sentence in sentences for word in sentence if len(sentence)>1]))) # Skip one-word sentences to avoid zero-vectors\n",
    "    countMatrix = get_count_matrix(sentences = sentences, vocabulary = vocabulary, windowSize = 7)\n",
    "    randomMatrix = get_random_matrix(dim = 100, vocabulary = vocabulary)\n",
    "    embeddingSpace = get_embedding_space(countMatrix = countMatrix, randomMatrix = randomMatrix, l2 = True, mc = True)\n",
    "    embeddingSpace.save('../embedding/RI/russia/'+re.sub(\"\\.txt\", \"\",file)+'.npz') # save embedding\n",
    "    ## Calculate similarity\n",
    "    sm = []\n",
    "    for pair in all_pairs:\n",
    "        #print(all_pairs[j])\n",
    "        sm.append(get_simi(embeddingSpace = embeddingSpace, wd1 = pair[0], wd2 = pair[1]))\n",
    "    results.append(sm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_df = pd.DataFrame(results)\n",
    "pair_names = pd.DataFrame(all_pairs)\n",
    "rs_df2 = pd.concat([pair_names, rs_df.T], axis=1)\n",
    "rs_df2.to_csv(\"../results/simi_russia01-52_RI_non-neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['covid_usa_week01_2020-01-24.txt',\n",
       " 'covid_usa_week02_2020-01-31.txt',\n",
       " 'covid_usa_week03_2020-02-07.txt',\n",
       " 'covid_usa_week04_2020-02-14.txt',\n",
       " 'covid_usa_week05_2020-02-21.txt',\n",
       " 'covid_usa_week06_2020-02-28.txt',\n",
       " 'covid_usa_week07_2020-03-06.txt',\n",
       " 'covid_usa_week08_2020-03-13.txt',\n",
       " 'covid_usa_week09_2020-03-20.txt',\n",
       " 'covid_usa_week10_2020-03-27.txt',\n",
       " 'covid_usa_week11_2020-04-03.txt',\n",
       " 'covid_usa_week12_2020-04-10.txt',\n",
       " 'covid_usa_week13_2020-04-17.txt',\n",
       " 'covid_usa_week14_2020-04-24.txt',\n",
       " 'covid_usa_week15_2020-05-01.txt',\n",
       " 'covid_usa_week16_2020-05-08.txt',\n",
       " 'covid_usa_week17_2020-05-15.txt',\n",
       " 'covid_usa_week18_2020-05-22.txt',\n",
       " 'covid_usa_week19_2020-05-29.txt',\n",
       " 'covid_usa_week20_2020-06-05.txt',\n",
       " 'covid_usa_week21_2020-06-12.txt',\n",
       " 'covid_usa_week22_2020-06-19.txt',\n",
       " 'covid_usa_week23_2020-06-26.txt',\n",
       " 'covid_usa_week24_2020-07-03.txt',\n",
       " 'covid_usa_week25_2020-07-10.txt',\n",
       " 'covid_usa_week26_2020-07-17.txt',\n",
       " 'covid_usa_week27_2020-07-24.txt',\n",
       " 'covid_usa_week28_2020-07-31.txt',\n",
       " 'covid_usa_week29_2020-08-07.txt',\n",
       " 'covid_usa_week30_2020-08-14.txt',\n",
       " 'covid_usa_week31_2020-08-21.txt',\n",
       " 'covid_usa_week32_2020-08-28.txt',\n",
       " 'covid_usa_week33_2020-09-04.txt',\n",
       " 'covid_usa_week34_2020-09-11.txt',\n",
       " 'covid_usa_week35_2020-09-18.txt',\n",
       " 'covid_usa_week36_2020-09-25.txt',\n",
       " 'covid_usa_week37_2020-10-02.txt',\n",
       " 'covid_usa_week38_2020-10-09.txt',\n",
       " 'covid_usa_week39_2020-10-16.txt',\n",
       " 'covid_usa_week40_2020-10-23.txt',\n",
       " 'covid_usa_week41_2020-10-30.txt',\n",
       " 'covid_usa_week42_2020-11-06.txt',\n",
       " 'covid_usa_week43_2020-11-13.txt',\n",
       " 'covid_usa_week44_2020-11-20.txt',\n",
       " 'covid_usa_week45_2020-11-27.txt',\n",
       " 'covid_usa_week46_2020-12-04.txt',\n",
       " 'covid_usa_week47_2020-12-11.txt',\n",
       " 'covid_usa_week48_2020-12-18.txt',\n",
       " 'covid_usa_week49_2020-12-25.txt',\n",
       " 'covid_usa_week50_2021-01-01.txt',\n",
       " 'covid_usa_week51_2021-01-08.txt',\n",
       " 'covid_usa_week52_2021-01-15.txt']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../data_week_text/usa')\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_usa_week01_2020-01-24.txt\n",
      "covid_usa_week02_2020-01-31.txt\n",
      "covid_usa_week03_2020-02-07.txt\n",
      "covid_usa_week04_2020-02-14.txt\n",
      "covid_usa_week05_2020-02-21.txt\n",
      "covid_usa_week06_2020-02-28.txt\n",
      "covid_usa_week07_2020-03-06.txt\n",
      "covid_usa_week08_2020-03-13.txt\n",
      "covid_usa_week09_2020-03-20.txt\n",
      "covid_usa_week10_2020-03-27.txt\n",
      "covid_usa_week11_2020-04-03.txt\n",
      "covid_usa_week12_2020-04-10.txt\n",
      "covid_usa_week13_2020-04-17.txt\n",
      "covid_usa_week14_2020-04-24.txt\n",
      "covid_usa_week15_2020-05-01.txt\n",
      "covid_usa_week16_2020-05-08.txt\n",
      "covid_usa_week17_2020-05-15.txt\n",
      "covid_usa_week18_2020-05-22.txt\n",
      "covid_usa_week19_2020-05-29.txt\n",
      "covid_usa_week20_2020-06-05.txt\n",
      "covid_usa_week21_2020-06-12.txt\n",
      "covid_usa_week22_2020-06-19.txt\n",
      "covid_usa_week23_2020-06-26.txt\n",
      "covid_usa_week24_2020-07-03.txt\n",
      "covid_usa_week25_2020-07-10.txt\n",
      "covid_usa_week26_2020-07-17.txt\n",
      "covid_usa_week27_2020-07-24.txt\n",
      "covid_usa_week28_2020-07-31.txt\n",
      "covid_usa_week29_2020-08-07.txt\n",
      "covid_usa_week30_2020-08-14.txt\n",
      "covid_usa_week31_2020-08-21.txt\n",
      "covid_usa_week32_2020-08-28.txt\n",
      "covid_usa_week33_2020-09-04.txt\n",
      "covid_usa_week34_2020-09-11.txt\n",
      "covid_usa_week35_2020-09-18.txt\n",
      "covid_usa_week36_2020-09-25.txt\n",
      "covid_usa_week37_2020-10-02.txt\n",
      "covid_usa_week38_2020-10-09.txt\n",
      "covid_usa_week39_2020-10-16.txt\n",
      "covid_usa_week40_2020-10-23.txt\n",
      "covid_usa_week41_2020-10-30.txt\n",
      "covid_usa_week42_2020-11-06.txt\n",
      "covid_usa_week43_2020-11-13.txt\n",
      "covid_usa_week44_2020-11-20.txt\n",
      "covid_usa_week45_2020-11-27.txt\n",
      "covid_usa_week46_2020-12-04.txt\n",
      "covid_usa_week47_2020-12-11.txt\n",
      "covid_usa_week48_2020-12-18.txt\n",
      "covid_usa_week49_2020-12-25.txt\n",
      "covid_usa_week50_2021-01-01.txt\n",
      "covid_usa_week51_2021-01-08.txt\n",
      "covid_usa_week52_2021-01-15.txt\n"
     ]
    }
   ],
   "source": [
    "## generate embedding spaces with all data\n",
    "results = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    ## RI embedding\n",
    "    sentences = PathLineSentences('../data_week_text/usa/'+file)\n",
    "    vocabulary = sorted(list(set([word for sentence in sentences for word in sentence if len(sentence)>1]))) # Skip one-word sentences to avoid zero-vectors\n",
    "    countMatrix = get_count_matrix(sentences = sentences, vocabulary = vocabulary, windowSize = 7)\n",
    "    randomMatrix = get_random_matrix(dim = 100, vocabulary = vocabulary)\n",
    "    embeddingSpace = get_embedding_space(countMatrix = countMatrix, randomMatrix = randomMatrix, l2 = True, mc = True)\n",
    "    embeddingSpace.save('../embedding/RI/usa/'+re.sub(\"\\.txt\", \"\",file)+'.npz') # save embedding\n",
    "    ## Calculate similarity\n",
    "    sm = []\n",
    "    for pair in all_pairs:\n",
    "        #print(all_pairs[j])\n",
    "        sm.append(get_simi(embeddingSpace = embeddingSpace, wd1 = pair[0], wd2 = pair[1]))\n",
    "    results.append(sm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_df = pd.DataFrame(results)\n",
    "pair_names = pd.DataFrame(all_pairs)\n",
    "rs_df2 = pd.concat([pair_names, rs_df.T], axis=1)\n",
    "rs_df2.to_csv(\"../results/simi_usa01-52_RI_non-neg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
