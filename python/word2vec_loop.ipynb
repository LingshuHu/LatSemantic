{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Word2vec\n",
    "import gensim\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method EnglishStemmer.stem of <EnglishStemmer>>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words2 = stop_words[35:] # include i, we, they, it, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=True):\n",
    "    # remove link, user and special characters\n",
    "    #text = re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', str(text).lower()).strip()\n",
    "    # Remove link\n",
    "    #text = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', text, flags=re.MULTILINE) # to remove links that start with HTTP/HTTPS in the tweet\n",
    "    #text = re.sub(r'[-a-zA-Z0–9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0–9@:%_\\+.~#?&//=]*)', '', text, flags=re.MULTILINE) # to remove other url links\n",
    "    text = re.sub(r'https?:\\S+|http?:\\S', ' ', str(text).lower()).strip()\n",
    "    # change all to covid19\n",
    "    text = re.sub(r'(covid|c|cv)(\\s+|\\-|\\_)19', 'covid19 ', text)\n",
    "    text = re.sub(r'covid(\\s+|\\W|$)', 'covid19 ', text)\n",
    "    text = re.sub(r'coronavirus|caronavirus', 'covid19 ', text)\n",
    "    text = re.sub(r'corona', 'covid19 ', text)\n",
    "    text = re.sub(r'rona', 'covid19 ', text)\n",
    "    text = re.sub(r'c\\-19|c19|cv19|cv\\-19', 'covid19 ', text)\n",
    "    #text = re.sub(r'vaccinate|vaccination', 'vaccine', text)\n",
    "    #text = re.sub(r'depopulate', 'depopulation', text)\n",
    "    #text = re.sub(r'africa(n)?|melanin', 'black ', text)\n",
    "    #text = re.sub(r'immune', 'immunity', text)\n",
    "    text = re.sub(r'chip|microchipping', 'microchip', text)\n",
    "    #text = re.sub(r'deaths', 'death', text)\n",
    "    text = re.sub(r'laboratory', 'lab', text)\n",
    "    \n",
    "    # remove puctuations and special characters\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # remove first space\n",
    "    text = re.sub(r'^\\s+', '', text)\n",
    "    # Removing prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words2:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artilleri armor resist studi studi trump covid19 covid19 covid19 covid19 covid19 covid19 covid19 covid19 virus covid19'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"artillery armor resist study studied @trump covid 19 and! covid-19. and, ...covid_19, and #covid? c19 c 19 cv-19 covid19-virus coronavirus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black black'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"african and africa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('../data_week/russia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 13072)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    textp = []\n",
    "    for i in range(len(df.text)):\n",
    "        textp.append(preprocess(df.text.values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_russia_week1_2020-1-24.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-67e4893881cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../results/russia/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".w2v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    print(files[i])\n",
    "    df = pd.read_csv('../data_week/russia/'+files[i], encoding = \"ISO-8859-1\")\n",
    "    textp = df.text.apply(lambda x: preprocess(x))\n",
    "    documents = [_text.split() for _text in textp] \n",
    "    w2v_model = gensim.models.word2vec.Word2Vec(size=100, \n",
    "                                            window=7, \n",
    "                                            min_count=10, \n",
    "                                            workers=8)\n",
    "    w2v_model.build_vocab(documents)\n",
    "    words = w2v_model.wv.vocab.keys()\n",
    "    vocab_size = len(words)\n",
    "    w2v_model.train(documents, total_examples=len(documents), epochs=32)\n",
    "    w2v_model.save(\"../results/russia/\"+re.sub(\"\\.csv\", \"\",files[i])+\".w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('../data_week/usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_usa_week1.csv\n",
      "covid_usa_week6_2020-2-28.csv\n",
      "covid_usa_week10_2020-3-27.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingshu/anaconda3/envs/my_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_usa_week5.csv\n",
      "covid_usa_week9_2020-3-20.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingshu/anaconda3/envs/my_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_usa_week8_2020-3-13.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingshu/anaconda3/envs/my_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_usa_week3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingshu/anaconda3/envs/my_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_usa_week4.csv\n",
      "covid_usa_week2.csv\n",
      "covid_usa_week7_2020-3-6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingshu/anaconda3/envs/my_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    print(files[i])\n",
    "    df = pd.read_csv('../data_week/usa/'+files[i], encoding = \"ISO-8859-1\")\n",
    "    textp = df.text.apply(lambda x: preprocess(x))\n",
    "    documents = [_text.split() for _text in textp] \n",
    "    w2v_model = gensim.models.word2vec.Word2Vec(size=100, \n",
    "                                            window=7, \n",
    "                                            min_count=10, \n",
    "                                            workers=8)\n",
    "    w2v_model.build_vocab(documents)\n",
    "    words = w2v_model.wv.vocab.keys()\n",
    "    vocab_size = len(words)\n",
    "    w2v_model.train(documents, total_examples=len(documents), epochs=32)\n",
    "    w2v_model.save(\"../results/usa/\"+re.sub(\"\\.csv\", \"\",files[i])+\".w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new target corpor ceo brian cornel issu statement covid19 weekend we start limit number key item per purchas allow guest get they need covid19 covid19'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textp[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv(\"../data/covid_usa_jan24-mar10_21pm-23pm_onethird_text.csv\", encoding = \"ISO-8859-1\")\n",
    "#df = pd.read_csv(\"../data/covid_usa_mar11-may25_21pm-23pm_onethird_text.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 0 ns, total: 30.9 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# clean texts\n",
    "textp = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(textp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textp.rename = [\"textp\"]\n",
    "df = pd.concat([df, textp], axis=1)\n",
    "df.columns = [\"user_id\", \"status_id\", \"created_at\", \"screen_name\", \"text\", \"textp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x948078367</td>\n",
       "      <td>x1232793538569457664</td>\n",
       "      <td>2020-02-26 22:24:18</td>\n",
       "      <td>srmduke87</td>\n",
       "      <td>â¼ï¸\\nAzar refuses to promise a coronavirus ...</td>\n",
       "      <td>â ¼ï azar refuses promise covid19 vaccine affo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x14317928</td>\n",
       "      <td>x1232787852473270277</td>\n",
       "      <td>2020-02-26 22:01:42</td>\n",
       "      <td>rawells</td>\n",
       "      <td>The significance of the Miami man who feared h...</td>\n",
       "      <td>significance miami man feared he might covid19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x836361828494094336</td>\n",
       "      <td>x1233150596481536000</td>\n",
       "      <td>2020-02-27 22:03:07</td>\n",
       "      <td>DuckyTetzloff</td>\n",
       "      <td>Pocahontas: I'm gonna introduce a plan to take...</td>\n",
       "      <td>pocahontas i gonna introduce plan take every d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x61170702</td>\n",
       "      <td>x1233154633746538497</td>\n",
       "      <td>2020-02-27 22:19:10</td>\n",
       "      <td>discovertlife</td>\n",
       "      <td>California health officials are monitoring 8,4...</td>\n",
       "      <td>california health officials monitoring 8 400 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x371981714</td>\n",
       "      <td>x1233138902061535233</td>\n",
       "      <td>2020-02-27 21:16:39</td>\n",
       "      <td>RhondaJonesLevy</td>\n",
       "      <td>Republicans who acquitted Trump on articles of...</td>\n",
       "      <td>republicans acquitted trump articles impeachme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379345</th>\n",
       "      <td>x2181460182</td>\n",
       "      <td>x1236396565444669440</td>\n",
       "      <td>2020-03-07 21:01:26</td>\n",
       "      <td>4nnette_</td>\n",
       "      <td>Trump lied about Russian interference. He atta...</td>\n",
       "      <td>trump lied russian interference he attacked an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379346</th>\n",
       "      <td>x1177400099648880640</td>\n",
       "      <td>x1236038831859617792</td>\n",
       "      <td>2020-03-06 21:19:56</td>\n",
       "      <td>Carolyn83103672</td>\n",
       "      <td>@ThisisShannonVB @madisongesiotto He should be...</td>\n",
       "      <td>thisisshannonvb madisongesiotto he forced star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379347</th>\n",
       "      <td>x20032020</td>\n",
       "      <td>x1237124910603890688</td>\n",
       "      <td>2020-03-09 21:15:38</td>\n",
       "      <td>LLight</td>\n",
       "      <td>@GOP @GOPHouse @GOPSenate @SenatorCollins @Tho...</td>\n",
       "      <td>gop gophouse gopsenate senatorcollins thomtill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379348</th>\n",
       "      <td>x784494741153013760</td>\n",
       "      <td>x1237140816512135169</td>\n",
       "      <td>2020-03-09 22:18:50</td>\n",
       "      <td>captainleebip</td>\n",
       "      <td>Democrat Gavin Newsome was asked how President...</td>\n",
       "      <td>democrat gavin newsome asked president trump h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379349</th>\n",
       "      <td>x17703035</td>\n",
       "      <td>x1236038316463722496</td>\n",
       "      <td>2020-03-06 21:17:53</td>\n",
       "      <td>DonMcKenzie</td>\n",
       "      <td>The #coronavirus issue, over-hyped or not, has...</td>\n",
       "      <td>covid19 issue hyped show desperate need medica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379350 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_id             status_id           created_at  \\\n",
       "0                 x948078367  x1232793538569457664  2020-02-26 22:24:18   \n",
       "1                  x14317928  x1232787852473270277  2020-02-26 22:01:42   \n",
       "2        x836361828494094336  x1233150596481536000  2020-02-27 22:03:07   \n",
       "3                  x61170702  x1233154633746538497  2020-02-27 22:19:10   \n",
       "4                 x371981714  x1233138902061535233  2020-02-27 21:16:39   \n",
       "...                      ...                   ...                  ...   \n",
       "379345           x2181460182  x1236396565444669440  2020-03-07 21:01:26   \n",
       "379346  x1177400099648880640  x1236038831859617792  2020-03-06 21:19:56   \n",
       "379347             x20032020  x1237124910603890688  2020-03-09 21:15:38   \n",
       "379348   x784494741153013760  x1237140816512135169  2020-03-09 22:18:50   \n",
       "379349             x17703035  x1236038316463722496  2020-03-06 21:17:53   \n",
       "\n",
       "            screen_name                                               text  \\\n",
       "0             srmduke87  â¼ï¸\\nAzar refuses to promise a coronavirus ...   \n",
       "1               rawells  The significance of the Miami man who feared h...   \n",
       "2         DuckyTetzloff  Pocahontas: I'm gonna introduce a plan to take...   \n",
       "3         discovertlife  California health officials are monitoring 8,4...   \n",
       "4       RhondaJonesLevy  Republicans who acquitted Trump on articles of...   \n",
       "...                 ...                                                ...   \n",
       "379345         4nnette_  Trump lied about Russian interference. He atta...   \n",
       "379346  Carolyn83103672  @ThisisShannonVB @madisongesiotto He should be...   \n",
       "379347           LLight  @GOP @GOPHouse @GOPSenate @SenatorCollins @Tho...   \n",
       "379348    captainleebip  Democrat Gavin Newsome was asked how President...   \n",
       "379349      DonMcKenzie  The #coronavirus issue, over-hyped or not, has...   \n",
       "\n",
       "                                                     text  \n",
       "0       â ¼ï azar refuses promise covid19 vaccine affo...  \n",
       "1          significance miami man feared he might covid19  \n",
       "2       pocahontas i gonna introduce plan take every d...  \n",
       "3       california health officials monitoring 8 400 p...  \n",
       "4       republicans acquitted trump articles impeachme...  \n",
       "...                                                   ...  \n",
       "379345  trump lied russian interference he attacked an...  \n",
       "379346  thisisshannonvb madisongesiotto he forced star...  \n",
       "379347  gop gophouse gopsenate senatorcollins thomtill...  \n",
       "379348  democrat gavin newsome asked president trump h...  \n",
       "379349  covid19 issue hyped show desperate need medica...  \n",
       "\n",
       "[379350 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in textp] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.read_csv(\"../data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get words frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check weird words\n",
    "for i in range(len(textp)):\n",
    "    if textp[i].find(\"covid19virus\")>-1:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 991 ms, sys: 0 ns, total: 991 ms\n",
      "Wall time: 989 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in textp] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 88 ms, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# obtain words frequency\n",
    "# less effecient\n",
    "all_words = []\n",
    "for tweet in range(len(documents)):\n",
    "    for word in documents[tweet]:\n",
    "        all_words.append(word)\n",
    "        \n",
    "c = Counter(all_words)\n",
    "c200 = c.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.14 s, sys: 716 ms, total: 9.85 s\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# obtain words frequency\n",
    "words = []\n",
    "for t in textp:\n",
    "    words += t.split()\n",
    "\n",
    "c = Counter(words)\n",
    "c200 = c.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/mar11-may25_common_words200.txt\", \"w\") as fp:\n",
    "    json.dump(c200, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/jan24-mar10_common_words200.txt\") as fp:\n",
    "    c200_1 = json.load(fp)\n",
    "with open(\"../results/mar11-may25_common_words200.txt\") as fp:\n",
    "    c200_2 = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw1 = pd.DataFrame(data=c200_1)\n",
    "fw2 = pd.DataFrame(data=c200_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = pd.concat([fw1, fw2], axis = 1)\n",
    "fw.columns = [\"jan24-mar10\", \"jan24-mar10_freq\", \"mar11-may25\", \"mar11-may25_freq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw.to_csv(\"../results/words_frequency_top200.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=100, \n",
    "                                            window=7, \n",
    "                                            min_count=10, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 19526\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)\n",
    "words = w2v_model.wv.vocab.keys()\n",
    "#print(len(w2v_model.wv[\"u\"]))\n",
    "#print(list(w2v_model.wv.vocab.items())[0:5])\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"../results/jan24-mar10_w2vmodel_7window.w2v\")\n",
    "#w2v_model.save(\"../results/mar11-may25_w2vmodel_7window.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingshu/anaconda3/envs/my_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('virus', 0.7791696190834045),\n",
       " ('it', 0.6020281910896301),\n",
       " ('â', 0.4675745964050293),\n",
       " ('we', 0.45767682790756226),\n",
       " ('unfortunately', 0.4559614062309265),\n",
       " ('unreported', 0.4474548399448395),\n",
       " ('yet', 0.44092321395874023),\n",
       " ('disease', 0.4294845461845398),\n",
       " ('they', 0.40226098895072937),\n",
       " ('thus', 0.395939439535141)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"covid19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([[1, 0, -1]], [[-1,-1, 0]])\n",
    "type([[1, 0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model1 = gensim.models.Word2Vec.load(\"../results/jan24-mar12_w2vmodel.w2v\")\n",
    "w2v_model2 = gensim.models.Word2Vec.load(\"../results/mar13-may25_w2vmodel.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simi_compare(word1, word2):\n",
    "    wd11 = w2v_model1.wv[word1]\n",
    "    wd12 = w2v_model1.wv[word2]\n",
    "    wd21 = w2v_model2.wv[word1]\n",
    "    wd22 = w2v_model2.wv[word2]\n",
    "    print(\"jan24-mar12: \", cosine_similarity([wd11], [wd12]))\n",
    "    print(\"mar13-may25: \", cosine_similarity([wd21], [wd22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jan24-mar12:  [[-0.02310156]]\n",
      "mar13-may25:  [[-0.00771967]]\n"
     ]
    }
   ],
   "source": [
    "# china, cases, death, asian, black, distance, hoax\n",
    "# metaphors, distrust, misinformation\n",
    "\n",
    "\n",
    "simi_compare(\"covid19\", \"mistrust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01677959]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd1 = w2v_model.wv[\"covid19\"]\n",
    "wd2 = w2v_model.wv[\"china\"]\n",
    "cosine_similarity([wd1], [wd2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('coronavirus', 1), ('covid19', 2), ('trump', 3), ('people', 4), ('health', 5), ('amp', 6), ('us', 7), ('virus', 8), ('china', 9), ('cases', 10)]\n",
      "Total words 101545\n",
      "CPU times: user 9.04 s, sys: 3.64 ms, total: 9.04 s\n",
      "Wall time: 9.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.textp)\n",
    "print(list(tokenizer.word_index.items())[0:10])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE)) #Return a new array of given shape and type, filled with zeros.\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)\n",
    "print(len(embedding_matrix[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
