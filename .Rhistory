## read data
rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
## read data
df <- rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
View(df)
dv <- quanteda::dfm(df$text)
install.packages("quanteda")
dv <- quanteda::dfm(df$text.1)
quanteda::textstat_simil(d[, c("covid19", "china")],  method = "cosine", margin = "features")
quanteda::textstat_simil(dv[, c("covid19", "china")],  method = "cosine", margin = "features")
s <- quanteda::textstat_simil(dv[, c("covid19", "china")],  method = "cosine", margin = "features")
View(s)
s
s$Dimnames
s@x
s@Dimnames
s@x[2]
## read data
df <- rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
dv <- quanteda::dfm(df$text.1)
s <- quanteda::textstat_simil(dv[, c("covid19", "china")],  method = "cosine", margin = "features")
s@x[2] ## extract the similarity score
s <- quanteda::textstat_simil(dv[, c("covid19", "us")],  method = "cosine", margin = "features")
s@x[2] ## extract the similarity score
s <- quanteda::textstat_simil(dv[, c("covid19", "usa")],  method = "cosine", margin = "features")
s@x[2] ## extract the similarity score
df1 <- df
dv1 <- dv
rm(dv)
rm(df)
rm(s)
df_racemis <- dplyr::full_join(race, racemis)
race <- c("black", "africa", "african", "melanin", "poc")
racemis <- c("genocide", "immune", "immunity", "inoculated", "depopulate", "depopulation", "vitamin", "vit", "zinc", "supplements", "garlic", "water", "colloid", "vaccine", "vaccinate", "vaccination")
df_racemis <- dplyr::full_join(race, racemis)
df_racemis <- dplyr::full_join(data.frame(race), data.frame(racemis))
race_pair <- tidyr::crossing(race, racemis)
View(race_pair)
race <- c("black", "melanin", "poc")
racemis <- c("genocide", "immunity", "inoculated", "depopulation", "vitamin", "vit", "zinc", "supplements", "garlic", "water", "colloid", "vaccine")
race_pair <- tidyr::crossing(race, racemis)
View(race_pair)
covidmis = "unreported, 5G, radiation, electromagnetic, Chip, microchip, microchipping, implant, Gates, Hoax, Overblown, flu, Bleach, chlorine, Antibiotics"
covidmis <- "unreported, 5G, radiation, electromagnetic, Chip, microchip, microchipping, implant, Gates, Hoax, Overblown, flu, Bleach, chlorine, Antibiotics"
covidmis <- strsplit(covidmis, split = ", ")
covidmis <- "unreported, 5G, radiation, electromagnetic, Chip, microchip, microchipping, implant, Gates, Hoax, Overblown, flu, Bleach, chlorine, Antibiotics"
covidmis <- unlist(strsplit(tolower(covidmis), split = ", "))
covidmis
covid_pair <- tidyr::crossing("covid19", covidmis)
View(covid_pair)
?textstat_simil
s1 <- quanteda::textstat_simil(covid_pair,  method = "cosine", margin = "features")
dv1[, covid_pair[1, ]]
covid_pair[1, ]
dv1[, c(covid_pair[1, ])]
c(covid_pair[1, ])
dv1[, c(covid_pair[1, ][1])]
c(covid_pair[1, 1], covid_pair[1,2])
View(covid_pair)
covid_pair <- tidyr::crossing(covid19 = "covid19", covidmis)
View(covid_pair)
covid_pair[1, 1]
covid_pair[1, 1][1]
as.vector(covid_pair[1, ])
covid_pair[[1,]]
covid_pair[1, ][[1]]
covid_pair[1, ][[1:2]]
covid_pair[1, ][[2]]
covid_pair[[2]]
dv1[, c(covid_pair[[1]][1], covid_pair[[2][1]])]
dv1[, c(covid_pair[[1]][1], covid_pair[[2]][1])]
simi_compare <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(nrow(wordpairs))) {
vecs <- dfm[, c(wordpairs[[1]][i], wordpairs[[2]][i])]
s[i] <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
}
}
simi_compare <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(nrow(wordpairs))) {
vecs <- dfm[, c(wordpairs[[1]][i], wordpairs[[2]][i])]
s[i] <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
}
return(s)
}
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(nrow(wordpairs))) {
vecs <- dfm[, c(wordpairs[[1]][i], wordpairs[[2]][i])]
s[i] <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
}
return(s)
}
covid_s <- multi_simi(covid_pair, dv1)
View(covid_s)
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(nrow(wordpairs))) {
vecs <- dfm[, c(wordpairs[[1]][i], wordpairs[[2]][i])]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[i] <- obj@x[2]
}
return(s)
}
covid_s <- multi_simi(covid_pair, dv1)
View(covid_s)
5g %in% dv1
"5g" %in% dv1
dv1
View(dv1)
dv1@Dimnames
dv1@Dimnames$features
dv1[, "radiation"]
dv1[, "radiatisdfsd"]
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(nrow(wordpairs))) {
wd1 <- wordpairs[[1]][i]
wd2 <- wordpairs[[2]][i]
if (wd1 %in% dfm@Dimnames$features & wd2 %in% dfm@Dimnames$features) {
vecs <- dfm[, c(wordpairs[[1]][i], wordpairs[[2]][i])]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[i] <- obj@x[2]
} else {s[i] <- 9}
}
return(s)
}
covid_s <- multi_simi(covid_pair, dv1)
View(covid_s)
covid_s <- multi_simi(race_pair, dv1)
View(covid_s)
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(nrow(wordpairs))) {
wd1 <- wordpairs[[1]][i]
wd2 <- wordpairs[[2]][i]
if (wd1 %in% dfm@Dimnames$features & wd2 %in% dfm@Dimnames$features) {
vecs <- dfm[, c(wd1, wd2)]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[[i]] <- obj@x[2]
} else {s[[i]] <- 9}
}
return(s)
}
covid_s <- multi_simi(race_pair, dv1)
View(covid_s)
s <- vector("list", length = nrow(race_pair))
for (i in seq_along(nrow(race_pair))) {
wd1 <- race_pair[[1]][i]
wd2 <- race_pair[[2]][i]
if (wd1 %in% dfm@Dimnames$features & wd2 %in% dfm@Dimnames$features) {
vecs <- dfm[, c(wd1, wd2)]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[[i]] <- obj@x[2]
} else {s[[i]] <- 9}
}
s <- vector("list", length = nrow(race_pair))
for (i in seq_along(nrow(race_pair))) {
wd1 <- race_pair[[1]][i]
wd2 <- race_pair[[2]][i]
if (wd1 %in% dv1@Dimnames$features & wd2 %in% dv1@Dimnames$features) {
vecs <- dv1[, c(wd1, wd2)]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[[i]] <- obj@x[2]
} else {s[[i]] <- 9}
}
unlist(s)
seq_along(nrow(race_pair))
seq_along(race_pair)
?seq_along
nrow(race_pair)
seq_along(36)
seq_along(length(36))
seq_along(length=36)
seq_along(from =1, to=36)
seq_along(race_pair[[1]])
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(nrow(wordpairs[[1]]))) {
wd1 <- wordpairs[[1]][i]
wd2 <- wordpairs[[2]][i]
if (wd1 %in% dfm@Dimnames$features & wd2 %in% dfm@Dimnames$features) {
vecs <- dfm[, c(wd1, wd2)]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[[i]] <- obj@x[2]
} else {s[[i]] <- 9}
}
return(s)
}
covid_s <- multi_simi(race_pair, dv1)
View(covid_s)
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(wordpairs[[1]])) {
wd1 <- wordpairs[[1]][i]
wd2 <- wordpairs[[2]][i]
if (wd1 %in% dfm@Dimnames$features & wd2 %in% dfm@Dimnames$features) {
vecs <- dfm[, c(wd1, wd2)]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[[i]] <- obj@x[2]
} else {s[[i]] <- 9}
}
return(s)
}
covid_s <- multi_simi(race_pair, dv1)
View(covid_s)
covid_s <- unlist(multi_simi(race_pair, dv1))
race_pair_simi <- data.frame(race_pair, before = covid_s)
View(race_pair_simi)
other_pair <- rbind(c(1,2), c(2,3))
other_pair <- data.frame(rbind(c(1,2), c(3,4)))
View(other_pair)
View(other_pair)
covid_pair <- tidyr::crossing(X1 = "covid19", X2 = covidmis)
race_pair <- tidyr::crossing(X1 = race, X2 = racemis)
other_pair <- data.frame(rbind(c("mandatory", "vaccine"), c("overcount", "death"), c("dioxide", "mask"), c("lab", "china")))
all_pairs <- rbind(covid_pair, race_pair, other_pair)
View(all_pairs)
all_pair <- rbind(covid_pair, race_pair, other_pair)
df2 <- rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
dv2 <- quanteda::dfm(df2$text.1)
View(df2)
## read data
df1 <- rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
df2 <- rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
dv1 <- quanteda::dfm(df1$textp)
dv2 <- quanteda::dfm(df2$textp)
df2 <- rtweet::read_twitter_csv("data/covid_usa_mar11-may25_21pm-23pm_onethird_text_clean.csv")
dv2 <- quanteda::dfm(df2$textp)
## calculate similarities between all pairs
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(wordpairs[[1]])) {
wd1 <- wordpairs[[1]][i]
wd2 <- wordpairs[[2]][i]
if (wd1 %in% dfm@Dimnames$features & wd2 %in% dfm@Dimnames$features) {
vecs <- dfm[, c(wd1, wd2)]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[[i]] <- obj@x[2]
} else {s[[i]] <- 9}
}
return(s)
}
all_s1 <- unlist(multi_simi(all_pair, dv1))
all_s2 <- unlist(multi_simi(all_pair, dv2))
all_pair_simi <- data.frame(race_pair, before = all_s1, after = all_s2)
all_pair_simi <- data.frame(all_pair, before = all_s1, after = all_s2)
View(all_pair_simi)
write.csv(all_pair_simi, "results/covid_misinfo_onthot.csv")
write.csv(all_pair_simi, "results/covid_misinfo_onehot.csv")
## read data
df1 <- rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
df2 <- rtweet::read_twitter_csv("data/covid_usa_mar11-may25_21pm-23pm_onethird_text_clean.csv")
dv1 <- quanteda::dfm(df1$textp)
dv2 <- quanteda::dfm(df2$textp)
metaphor <- readLines("../data/keywords1.txt")
metaphor <- readLines("data/keywords1.txt")
metaphor
metaphor <- metaphor[1]
metaphor <- gsub('\\n+|\\s+', '', tolower(metaphor))
metaphor
metaphor <- strsplit(metaphor, split = ",")
View(metaphor)
metaphor <- unlist(strsplit(metaphor, split = ","))
metaphor <- readLines("data/keywords1.txt")
metaphor <- metaphor[1]
metaphor <- gsub('\\n+|\\s+', '', tolower(metaphor))
metaphor <- unlist(strsplit(metaphor, split = ","))
meta_pair <- tidyr::crossing(X1 = "covid19", X2 = metaphor)
View(meta_pair)
## calculate similarities between all pairs
multi_simi <- function(wordpairs, dfm) {
s <- vector("list", length = nrow(wordpairs))
for (i in seq_along(wordpairs[[1]])) {
wd1 <- wordpairs[[1]][i]
wd2 <- wordpairs[[2]][i]
if (wd1 %in% dfm@Dimnames$features & wd2 %in% dfm@Dimnames$features) {
vecs <- dfm[, c(wd1, wd2)]
obj <- quanteda::textstat_simil(vecs,  method = "cosine", margin = "features")
s[[i]] <- obj@x[2]
} else {s[[i]] <- 9}
}
return(s)
}
meta_s1 <- unlist(multi_simi(meta_pair, dv1))
meta_s2 <- unlist(multi_simi(meta_pair, dv2))
meta_pair_simi <- data.frame(meta_pair, before = meta_s1, after = meta_s2)
write.csv(meta_pair_simi, "results/covid_metaphor_onehot.csv")
df1 <- rtweet::read_twitter_csv("data/covid_usa_jan24-mar10_21pm-23pm_onethird_text_clean.csv")
grepl("army", "this is army")
grepl("army|covid", "this is army and covid")
grepl("army&]covid", "this is army and covid")
grepl("army&covid", "this is army and covid")
dfs <- df1[grepl("army", df1$textp)&grepl("covid19", df1$textp),]
dfs$textp[1:10]
dfs$text[1:10]
writeLines(dfs$text, "results/army&covid.txt")
txt <- dfs$text
txt <- data.frame(id = 1:403, text = dfs$text)
write.csv(txt, "results/army&covid.csv")
dfs<- dfs[!duplicated(dfs$textp), ]
txt <- data.frame(id = 1:203, text = dfs$text)
write.csv(txt, "results/army&covid.csv")
dfs <- df1[grepl("battles", df1$textp)&grepl("covid19", df1$textp),]
dfs <- dfs[!duplicated(dfs$textp), ]
txt <- data.frame(id = 1:30, text = dfs$text)
write.csv(txt, "results/battles&covid.csv")
dfs <- df1[grepl("radiation", df1$textp)&grepl("covid19", df1$textp),]
dfs <- dfs[!duplicated(dfs$textp), ]
df2 <- rtweet::read_twitter_csv("data/covid_usa_mar11-may25_21pm-23pm_onethird_text_clean.csv")
dfs <- df1[grepl("hoax", df1$textp)&grepl("covid19", df1$textp),]
dfs <- dfs[!duplicated(dfs$textp), ]
txt <- data.frame(id = nrow(dfs), text = dfs$text)
write.csv(txt, "results/hoax&covid.csv")
#####
files <- list.files("data_week/usa", full.names = T)
key_sample <- vector("list", length = length(files))
for (i in seq_along(files)) {
df <- rtweet::read_twitter_csv(files[i])
keydf <- df[grepl("frontlines?", df$text, ignore.case = T)&
grepl("covid19|covid|coronavirus", df$text, ignore.case = T),]
if (nrow(keydf) > 1000) {
set.seed(123)
keydf <- dplyr::sample_n(keydf, 1000)
}
key_sample[[i]] <- keydf
}
key_sample <- do.call("rbind", key_sample)
key_sample <- key_sample[!duplicated(key_sample$text), ]
rtweet::write_as_csv(key_sample, "sample_texts/frontline_week1-10.csv")
rtweet::write_as_csv(key_sample[, 1:5], "sample_texts/frontline_week1-10_texts.csv")
key_sample <- vector("list", length = length(files))
for (i in seq_along(files)) {
df <- rtweet::read_twitter_csv(files[i])
keydf <- df[grepl("5G", df$text, ignore.case = T)& #frontlines?
grepl("covid19|covid|coronavirus", df$text, ignore.case = T),]
if (nrow(keydf) > 1000) {
set.seed(123)
keydf <- dplyr::sample_n(keydf, 1000)
}
key_sample[[i]] <- keydf
}
key_sample <- do.call("rbind", key_sample)
key_sample <- key_sample[!duplicated(key_sample$text), ]
rtweet::write_as_csv(key_sample, "sample_texts/5g_week1-10.csv") # frontline
rtweet::write_as_csv(key_sample[, 1:5], "sample_texts/5g_week1-10_texts.csv")
key_sample <- vector("list", length = length(files))
for (i in seq_along(files)) {
df <- rtweet::read_twitter_csv(files[i])
keydf <- df[grepl("fight", df$text, ignore.case = T)& #frontlines?; 5G
grepl("covid19|covid|coronavirus", df$text, ignore.case = T),]
if (nrow(keydf) > 1000) {
set.seed(123)
keydf <- dplyr::sample_n(keydf, 1000)
}
key_sample[[i]] <- keydf
}
key_sample <- do.call("rbind", key_sample)
key_sample <- key_sample[!duplicated(key_sample$text), ]
rtweet::write_as_csv(key_sample, "sample_texts/fight_week1-10.csv") # frontline; 5g; fight
rtweet::write_as_csv(key_sample[, 1:5], "sample_texts/fight_week1-10_texts.csv")
key_sample <- vector("list", length = length(files))
for (i in seq_along(files)) {
df <- rtweet::read_twitter_csv(files[i])
keydf <- df[grepl("hoax", df$text, ignore.case = T)& #frontlines?; 5G; fight; hoax
grepl("covid19|covid|coronavirus", df$text, ignore.case = T),]
if (nrow(keydf) > 1000) {
set.seed(123)
keydf <- dplyr::sample_n(keydf, 1000)
}
key_sample[[i]] <- keydf
}
key_sample <- do.call("rbind", key_sample)
key_sample <- key_sample[!duplicated(key_sample$text), ]
rtweet::write_as_csv(key_sample, "sample_texts/hoax_week1-10.csv") # frontline; 5g; fight; hoax
rtweet::write_as_csv(key_sample[, 1:5], "sample_texts/hoax_week1-10_texts.csv")
key_sample <- vector("list", length = length(files))
for (i in seq_along(files)) {
df <- rtweet::read_twitter_csv(files[i])
keydf <- df[grepl("flu", df$text, ignore.case = T)& #frontlines?; 5G; fight; hoax; flu
grepl("covid19|covid|coronavirus", df$text, ignore.case = T),]
if (nrow(keydf) > 1000) {
set.seed(123)
keydf <- dplyr::sample_n(keydf, 1000)
}
key_sample[[i]] <- keydf
}
key_sample <- do.call("rbind", key_sample)
key_sample <- key_sample[!duplicated(key_sample$text), ]
rtweet::write_as_csv(key_sample, "sample_texts/flu_week1-10.csv") # frontline; 5g; fight; hoax; flu
rtweet::write_as_csv(key_sample[, 1:5], "sample_texts/flu_week1-10_texts.csv")
